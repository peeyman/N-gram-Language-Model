{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <p style='text-align:justify'>In this notebook, first I am going to talk about what is a language model. Then, I we be describing a specific class of language models called n-gram language model. Also, I will be implementing it using methods from a well-known natural language processing library, i.e. NLTK to get a better grasp of the concept by being practical.  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a language model? Let's look at the following sentence.\n",
    "\n",
    "**Long time no see. How have you ...**\n",
    "\n",
    "Can you guess what the next word would be? if you just guessed it to be **\"been\"**, then you already have an amazing language model built into your brain!\n",
    "\n",
    "<p style='text-align:justify'>So, how you were able to guess the next word in the above sentence? The answer is among many words in the language you gave a higher probability to the word **\"been\"** than any other words. And, you did it based on the context, based on the words that already there is the sentence. Actually, the example in the above sentence is an extreme caase. It is hard to think of any word than **\"been\"**. </p>\n",
    "\n",
    "Let's look at a less extreme case.\n",
    "\n",
    "**There is nothing as relaxing as ...**\n",
    "\n",
    "<p style='text-align:justify'>What are you going to fill in the blank with? There are many words you can think of, right? Like, reading, resting, having, taking, etc. You may think of many other words. Whatever word you are thinking of is because your language model assign a higher probability to them. (Assuming that our brain have a language model in the first place :D !)</p>\n",
    "\n",
    "<p style='text-align:justify'>So, basically a language model is a model that is able to assign probability to every possible word based on the words already exist in a sentence. This is one definition, another one is language model is a model that is able to assign probability to the entire sentence. Later I will show you how these two definitions are equivalent.\n",
    "The first definition can be cast as conditional probability, i.e probability of next work given the previous words. The second definition can be cast as joint probability, i.e joint probability of all the words in a sentence.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is mentioned one definition of a language model is that a language model is a model that is able to assign probability to an entire sentence. Let's consider the following sentence.\n",
    "\n",
    "** There is nothing as relaxing as reading a book.**\n",
    "\n",
    "The joint probability of this sentence can be expressed as:\n",
    "\n",
    "$$ P(X_1=\"There\",X_2=\"is\",X_3=\"nothing\",..., X_9=\"book\") $$\n",
    "\n",
    "or more generally for every sentence we want to calculate the following joint probability.\n",
    "\n",
    "$$ P(X_1=w_1,X_2=w_2,X_3=w_3,..., X_n=w_n) $$\n",
    "\n",
    "where $ w_i $ is the $ith$ word in a sentence.\n",
    "\n",
    "<p style='text-align:justify'>So, in the example sentence above there are 9 words. let's take a moment to think you can we calculate the joint probability of these words. One way of doing this is to count all the occurences of this sentence and also count all the possible sequence of nine words and then divide these two numbers. Or, in other words out of all possible sequence of 9 words, what percentage of them is exactly as the example sentence?  Is this approach practical? We need to calculate possible sequence of different length of sentences. Not only that, for every new sentence we need calculate how many times each sentence occured. It looks like huge amount of computations. Aside from computational complexity, another serious issue is that because language is so creative, many new sentences can be generated than never happened in our dataset. The problem is that just because they haven't occurred before we cannot simply assign probability of zero to them.</p>\n",
    "\n",
    "<p style='text-align:justify'>Due to the mentioned reasons there is a need for more intelligent way to calculate the probability of sentences. One clever way is to use **chain rule of probability** which is as follows.</p>\n",
    "\n",
    "$$ P(X_1,X_2,...,X_n) = P(X_1)\\:P(X_2|X_1)\\:P(X_3|X_1,X_2)...P(X_n|X_1,X_2,...X_{n-1})$$\n",
    "\n",
    "<p style='text-align:justify'>This rule turn joint probability into conditional probability. Which loosely speaking allows us to break the joint probability of all words in the sequence into smaller parts. Breaking things into smaller parts is a general approach of problem solving. Isn't it?</p>\n",
    "\n",
    "To be more concrete let's take the first there of our example sentence.\n",
    "\n",
    "\n",
    "**There is nothing**\n",
    "\n",
    "$$ P(X_1=\"There\",X_2=\"is\",X_3=\"nothing\") = \\\\ P(X_1=\"There\")\\:P(X_2=\"is\"|X_1=\"There\")\\:P(X_3=\"nothing\"|X_1=\"There\",X_2=\"is\")$$\n",
    "\n",
    "<p style='text-align:justify'>It seems great! Now we can calculate each term in the right side of the equation separately. For example to calculate the $ P(X_1=\"There\") $, we can count how many time the word \"**There**\" occured in our dataset and divide it by all possible occurrences of one words which is equivalent to the length of our corpus(dataset). Or to calculate $ P(X_3=\"nothing\"|X_1=\"There\",X_2=\"is\") $, we need to calculate how many time the word \"**nothing**\" occured after the two word combination of \"**There is**\" and then divide it by number of time \"**There is**\" happened in our dataset. It is clear to see that after \"**There is**\" many other words other than \"**nothing**\" can occur.</p>\n",
    "\n",
    "Up to now, everything looks fine! Let's go back to our full length example sentence.\n",
    "\n",
    "** There is nothing as relaxing as reading a book.**\n",
    "\n",
    "When we use the chain rule for this longer sentence for example the last part of the right hand side of the equation would be as follows.\n",
    "\n",
    "\n",
    "$$ P(\\text{ book | There is nothing as relaxing as reading a}) $$\n",
    "\n",
    "Note that for the sake of notation simplicity Xs are not written. \n",
    "\n",
    "<p style='text-align:justify'>What do we need to do to calculate this probability. The same as above we need to count number of time the sequence \"**There is nothing as relaxing as reading a**\" is occurred. Also number of the times that \"**book**\" appeared after \"**There is nothing as relaxing as reading a**\". But, isn't it the same problem as we we have in the joint probability calculation. Remember again that language is creative and the chance that a sequence of specific words happens can be zero or even if it is not zero due to the rare occurrence it might not capture the true probability.</p>\n",
    "    \n",
    "The problem is not completely solved. What can we do? That is where the n-gram model comes into play.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the conditional probability of a word given the past words or history which is the main building block of the chain rule of probability.\n",
    "\n",
    "$$ P(w_n|w_1,w_2,...,w_{n-1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>Now let's think of what is the main problem we had in calculating this. The problem arises when the length of sequence of past words are large. It it is short there will be no problem. For example in $ P(X_3=\"nothing\"|X_1=\"There\",X_2=\"is\") $ the history length is two which is short and because it is short probably this combinations occurs many times in our dataset. But when the history length is large the problem arises.</p>\n",
    "\n",
    "<p style='text-align:justify'>The whole intuition behind N-gram model is instead of calculating the probability of a word given its entire history, we can approximate the entire history by just the past few words. It is intuitive to see why this idea will help right? It is because we are avoiding long sequence of words with this trick.</p>\n",
    "\n",
    "<p style='text-align:justify'>Depending on the length of our N-gram model (N),i.e. with how many words we are going to approximate history, we can have bigram, trigram, 4-gram, 5-gram, etc. In other word, if N=2 then we will have bigram, if N=3 then we will have trigram, and so forth.</p>\n",
    "\n",
    "Mathematically, approximation of the history with the past few words can be expressed as follows.\n",
    "\n",
    "$$ P(w_1,w_2,...,w_n) \\simeq P(w_n|w_1,w_2,...,w_{n-N+1})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the use of above formula and chain rule of probability the **bigram** model can be written as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(w_1,w_2,...,w_n) \\simeq \\prod_{k=1}^{k=n} P(w_k|w_{k-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And each term inside the product at the right hand side of the equation can be calculated as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(w_n|w_{n-1}) = \\frac{Count(w_{n-1}w_n)}{Count(w_{n-1})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'> Bigram model assumes that the probability of a word depends only on the previous word. This assumption is called Markov assumption. More generally Markov models are the branch of probabilistic models that states that we can predict the probability of some future units without looking too much far in the past, rather just look at recent part of the history.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, in any N-gram model probability of a word given its past N words can be expressed as the ratio of two counts as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(w_n|w_{n-N+1}w_{n-N+2}...w_{n-1}) = \\frac{Count(w_{n-N+1}w_{n-N+2}...w_{n-1}w_n)}{Count(w_{n-N+1}w_{n-N+2}...w_{n-1})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>Let's be more concrete by considering a very small corpus of only three sentences and calculate some of the conditional terms in the bigram model. Note that twp special characters, $ \\text{<s> and </s>}$ which are start symbol and end symbol respectively are added to each sentence. It is kind of necessary to give context before the first word and after the last word in each sentence.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{<s> I read this book</s>}$\n",
    "\n",
    "$ \\text{<s> This book is very interesting</s>}$\n",
    "\n",
    "$ \\text{<s> I found it interesting since it is informative</s>}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(I|\\text{<s>}) = \\frac{2}{3} \\quad \\quad P(read\\:|\\:I)=\\frac{1}{2} \\quad \\quad P(since\\:|\\: interesing)=\\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to get our handy dirty and write some code to see everything in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>The main library I am going to use in this code is NLTK. It is one the leading platforms to work with natural languages in Python.  It provides more than 50 corpora and lexical resources and interfaces to work with them, also it provides text processing libraries including tokenization, stemming, parsing, classification and etc. Especially for our implementation we are going to use bigram and trigram libraries.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists lots of corporas in NLTK, but lets pick webtext corpora and work with it. In the following link you can learn about different corpora in NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to /home/peyman/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('webtext')\n",
    "from nltk import bigrams,trigrams\n",
    "from nltk.corpus import webtext\n",
    "from collections import Counter, defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>First, I am going to build a bigram model. Remember that in the bigram model we assume that the probability of each word depends only on its previous word. In order to build our model, let's define a nested dictionary. In this nested dictionary the outer one is going to maintain the previous word(s) in our n-gram model and and the inner dictionary is going to maintain the word to be predicted. In other words, outer dictionary contains previous context word(s) and the inner one contains target word.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>To do se, defaultdict library from collection package is used instead of original dict library of Python. The reason for choosing defaultdict over dict is that defaultdict will \"default\" a value if the key has not been set yet, which is actually the case in our model because before parsing the sentences we don't know keys. In other word, it is said that if we have some meaningful default values for our missing keys it is suitable to use defaultdict. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>Now, to build our bigram model we need to iterate over all sentences in our corpora. Then for each sentence we need to apply bigram and add it to dictionary. By adding to dictionary basically I mean counting the occurrences of combination of words.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in webtext.sents():\n",
    "    for w1,w2 in bigrams(sentence,pad_right=True,pad_left=True):\n",
    "        model[w1][w2] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>Note that the bigrams function in the above code takes a sentence and two arguments for padding left and right. This padding works the same way as I described augmenting our sentence with special start and end characters in our example. But instead of those characters this library pads it with None.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>In the above code snippet we made our dictionary. Now it is time to normalize it to convert it to a probability distribution for each key in the outer dictionary.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1 in model:\n",
    "    total_count = float(sum(model[w1].values()))\n",
    "    for w2 in model[w1]:\n",
    "        model[w1][w2] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>Up to know we built our bigram model. The interesting thing is that we can now use this model as a generative model to generate some novel sentences. To generate sentences first we need to start with a word, which it is natural to choose the start of sentence word, i.e None. Now, one method that we can use is search for the word in our dictionary that comes after None and has the highest probability (let's say it is \"I\"). For generating the next word then we select the next word that comes after \"I\" and has the highest probability. And we can continue until the the end of sentence character is generated. But there is a problem with this method. If we use this method every time we end up with the same sentence.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>To solve for the above problem instead we are going to use a sampling method. That is instead for selecting the word with the highest probability base on previous word, we are going to sample a word based on their probabilities. Using this method it is possible that a word with low probability will be selected, but from and expected value viewpoint mostly words with high probability are more probable to be selected.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>Concretely, the way it works is that first a random number in the range [0,1] is created, then we start adding the probability of every word cumulatively until that random number be greater or equal to the cumulative probability. Doing so, most of the times leads to selecting a word with high probability.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get your crib ...\n",
      "Why would compromise your body .\n",
      "Teen girl # 1 : But he goes to a woman in public .\n",
      "DENNIS : Ni !\n",
      "Dude : I am going to b0rk Contiaing URLS from Firebird a master password field does not escaped : Jesus !...\n",
      "Queer : Those people in Tabs - definable hotkeys optional download firefox gtk2 + xft .\n",
      "Dude : So I wonder if version ) javascript ) clicking compose When you can buy you hear a fishing , pure .\n",
      "With this is missing and tell me .\n",
      "Little boy : Yeah ?\n",
      "Okay , very much demi - Toddler : Well , quite weighty . 8 to scantily - barreled cannon covers New York .\n",
      "Chick : They look like Axl Rose - source .\n",
      "Right Click on him , but none of servitude , yeah , I know .\n",
      "So my favorite color mode Bookmarks Manager RFE : Oh , the other one - town on my wife ran away your sister : I ' ll go outside , rustic and stuff .\n",
      "html pages \" Find instead of Ni !\n",
      "Woman on you can take a gay friend too .\n",
      "Woman # 1 : Or whatever she ain ' s get that up one of an act of fucking funny . 9 !\n",
      "Get your master password manager expand when using coconuts and started giving error \" you , you . xul in gtk_xtbin_resize () in fact , I marry lots of his name does not fetch my whole hour ... BEDEVERE : Who is ok if you ?\n",
      "PINTEL : I can eat dinner , you quit .\n",
      "Girl # 1 second hand electric wheelchair which must be ?\n",
      "open new tab \" Save As ...\n",
      "Sista # 2 : I was like , thinkin ' s in background images fail to the elements Amazon fashionista : Which train out of room [ Will looking for weed makes all each tab resets contents Alt + 1t ) Very nice .\n",
      "High Street . 6 Pop - bottle on the whole Firefox is it ' t appear Would like fish .\n",
      "Someone shouldn ' s only am all over the left clicking one tab \" noshade \" My name exists Extensions settings in 26 and I don ' t be runnin ' t clear to install software Middle - less apparent way . R .?\n",
      "Random Girl # 1 : You ' s died ?\n",
      "-- she ' t go to ?\n",
      "Drunk black .\n",
      "Drunk guy # 2 stops working there ?\n",
      "*** Unforthcoming at 96th Street guy thinks it matter anyway ?\n",
      "), tangy , man this great place to his friend Queer on my god and all windows have to display Firefox builds Edit -> URL bar in the neck lift one in single tabs launch of the priest sucks so easy , boom ...\n",
      "Guy # 2 : And she ' re actually thinks I ' m not carry it .\n",
      "English girl , shame .\n",
      "Girl # 2 : So the same and bottled beers ?\n",
      "Little boy : Nah , man : Like a bit spirity .\n",
      "Guy : Hold on cell : Look !\n",
      "BEDEVERE : No system can wear crappy version Draw Problem string theory could be deletable using Other patient : Yes ?\n",
      "They could not appear to work without being picked it ' t worry about a day I ever seen you made it , let me in view source \" new one , liar .\n",
      "Hipster guy : Wow , the tall hipster guy : Ummm , balanced than the violent ?\n",
      "Chick on bags and walks back ] [ MacOS X locks up Firebird changes to you to my boyfriend ' t even a lot of a Mets fan : I ' t you speak gramatically correctly .\n",
      "Teen girl # 2 : ... Mmm , you , I was an Egyptian dude # 2 : Well , lady : Are all are nudie pictures icons improperly Mozilla Firebird 0 .\n",
      "Just ready to study abroad in the life .\n",
      "Little girl # 1 : Where ' s tellin ' s manacles , I can ' m crazy conversations right , I went to wrong .\n",
      "It ' t that .\n",
      "Brunette : Oh , all the default to crash while ?\n",
      "Delicious drinking wine .\n",
      "That ' t install themes will you see .\n",
      "Guy : two evenings as for the print - ass look back this three things ] [ Jack Sparrow sent to open Add UI text find someone who ?\n",
      "Let me more depths !\n",
      "Bill Pay your shit .\n",
      "Let me to make me to jail shit about the oral sex smell my hand cursor when maximized some gay !\n",
      "Woman # 1 Changing keyword .\n",
      "What they ' t touch decadent .\n",
      "RAGETTI : We ' ve been blocked on F3 doesn ' s got money on one .\n",
      "Excited teen # 2 : My butterfly !\n",
      "We are coming together .\n",
      "Bare *** Very refined , a bit rubbery but it ' ll never been a new Folder \" for *.\n",
      "Decent * Bright happy , you have to get \" flavours .\n",
      "Maybe .\n",
      "Guy : Well , 43 for it still kept saying something to spend a new window ( from exiting Office thug # 1 : Ah !\n",
      "Lindsay Lohan : ....... ok buttons in drop on the rules for ' t pull * think it ' m gonna beat us the human eyes .\"\n",
      "Vendor man : Well , I demand .\n",
      "I ' t met anyone know .\n",
      "Teen girl in tab and the conductor .\n",
      "Guy : Sword !\n",
      "Vegan smoker , oak on animals .\n",
      "Woman # 2 : copyright and someone ... unless maybe they want land .\n",
      "He ' t close after theme is in the time they ' t stick - aged female early stages of tabs ) Can ' cause , what ' s really tall 5 .\n",
      "100 % old do .\"\n",
      "Man : I may have , sir , I mean , stand for drinking .\n",
      "And I said .\n",
      "You aren ' re all singles . rdf inside me complaining about a Bookmarks has focus () should I was a button [ aerial view selection choices then you hang indefinitely until after manually ( disgorged June 2004 - like , good stage for a lubricant !\n",
      "Excuse me out of water to walk into the radio buttons Anchor ending firefox must have a knight to Tools > overlap with a witch .\n",
      "I would you ' m from Location bar , up on address when I have complexity .\n",
      "DAVY JONES : I don ' s minized or leave on Linux ] LAUNCELOT : Hey , yes . exe Missing in urls revert to call you ask before the program selection !\n",
      "[ clap clap clap clap clap ] VOICE : FUCK YOU LOVE to become large , they call it isn ' t sell - geev - wheel ] Scene : Let me alone in open in ascending order Radio Doesn ' ve decided to ?\n",
      "Woman # 2 : Do you , Rhode Island woman .\n",
      "A fuck !\n",
      "Conductor guy : Nigga hit him just know .\n",
      "firefox dowload page firefox to the the forest , your child page installing extension not identical browser unusable .\n",
      "alternate times Remove Help -> General tab always know what you anyways , rich , I talked to open * away in the girls in DOS window .\n",
      "Friend : Two bottles are corrupt with your special cuvee from Yahoo ][ Excite ] WILL TURNER : Hey , or losing .\n",
      "Girl # 1 : You can ' m not support depends on downloads Middle - see my parents named ... Three questions .\n",
      "I tried to MTA booth lady : The bookmark \" XP control !\n",
      "Girl : Babe Ruth and will not launch twice ( no reason .\n",
      "It ' s gonna go in a fire ; I want to troubleshoot the import settings page stylesheets css in the nose .\n",
      "Firebird or I ' t remember sorting ( tabs ALT + version of the transition to only have genital sores .\n",
      "Woman : What do you gonna be unable to use inline from bookmarks save a t care what I don ' re here , almost walked right click OK on placing itself .\n",
      "So did you seen .\n",
      "!\n",
      "Hobo # 1 : I mean someone out with the better , and put that ' t understand how we ' s evening with this is a station over , sir , um , sports .\n",
      "Hipster guy : I mean , that lesbian .\n",
      "Married Ok ... WILL TURNER : You oughta check this guy : Girl : Dude on - presumably not so disturbing .\n",
      "Come on it !\n",
      "Guy : You wanna hear me he ' t feel it ' s contents to connecting to the fuck up the Africans : I went to Ragetti are not really long , but only as to expand nor quicksearch bookmarks right , everybody a touch hard place .\n",
      "But many problems tracking bug system with .\n",
      "Girl : Damn , lacks options can get a lot more emotional , I ' s good *** Not even in his coffee and oily sort order in his head in window reorders spaces being overgenerous with you , you homosexuals and a Red Sox logo down firebird to live here , all of a \" not important things , maybe just wanna kill every one - UX 10 years ago .\n",
      "Yuppie woman : Wait , so I smoke ?...\n",
      "Excuse me , weird characters in Firefox should have anything .\n",
      "Woman # 2 : Fuck you have every time ahead - ahead and it ' t \" New Tab prefs checkbox is the anniversary of the chest .\n",
      "Man : I don ' s so I don ' cause of dog -- he said , I start page cannot believe ) switching theme disallows customizing toolbars URLs from a great things or c Delete searchplugins broken in Firefox without clicking multiple downloads sidebar if binaries reside on about .. I feel really good condition .\n",
      "That ' s my notes .\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    text = [None]\n",
    "\n",
    "    sentence_finished = False\n",
    "\n",
    "    word_prev = None\n",
    "    while not sentence_finished:\n",
    "        r = random.random()\n",
    "        accumulator = .0\n",
    "\n",
    "        for word in model[text[-1]].keys():\n",
    "            accumulator += model[text[-1]][word]\n",
    "\n",
    "            if accumulator >= r:\n",
    "                text.append(word)\n",
    "                break\n",
    "            word_prev = word\n",
    "\n",
    "        if text[-1] == None:\n",
    "            sentence_finished = True\n",
    "\n",
    "    print(' '.join([t for t in text if t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align:justify'>It is actually fun reading these generated sentences. Some of them make sense actually. But let's implement trigram and compare sentences between bigram and trigram. I personally expect that since trigram consider two words as history to predict the next word could produce more meaningful sentences.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suit on cell being way too brown to be ?\n",
      "Teen boy # 2 : But wait , did you tell it to be extracted after being yelled at by the way , although I could become a sheriff .\n",
      "Man : When will you find the man who was born barefoot in South America .\n",
      "Top **** Perfectly balanced mature Claret nose .\n",
      "Kid : So I had staph infections last year ?... 5 . 0 Ability to have checked out okay , man .\n",
      "FATHER : Make New York like a different charset RFE : Provide preference for rendering items requested by OS or OtherProgram Search should be slaughtered .\n",
      "I ' m so sorry .\n",
      "Drunk woman : No , we have a short story .\n",
      "Teen boy # 2 : I am\n",
      "This is not presented when adding bookmark from the Thundercats .\n",
      "The search for % s results Download - link doesn ' t you ?\n",
      "Teen girl : Why not ?\n",
      "Dude : I think I never realized it was gonna snow .\n",
      "Crazy guy : No , no ... Store lady : Does it look fake ?\n",
      "Just take a picture !\n",
      "Black chick : You know that she forgot !\n",
      "Mom : Excuse me , drink ' til vegoose .\n",
      "Woman # 2 : Yeah .\n",
      "Girl # 1 : All right !\n",
      "Oh , yeah , I have kids back to prison , bound to hang at full CPU usage ' copy link location ' should say ' sorry ' about ' em together .\n",
      "Guy # 2 : Yeah .\n",
      "Akeelah !\n",
      "Girl # 1 : Oh , I ' m in Manhattan , so I told you that I did give that girl ' s bottoms !\n",
      "*** Nice mature riesling nose .\n",
      "Because there are too narrow ( mostly with new window Fix sherlock plug - in needed \".\n",
      "Chick # 2 : No , it was me bein ' * nix script & a patch to bug # 225755 - the - moz - opacity makes things invisible on OS X ] Open in Tabs \" Needs a few years ago ?\n",
      "Look well , I ' d rather walk .\n",
      "Girl : I don ' t know .\n",
      "Vendor guy : I can ' t create working configs and loops with \"*** loading the page finishes loading Ctrl + Enter After Agent Switcher set to false Opening Options from Download Manager should be disabled Allways allow session cookies firebird ( sub -) window . clipboardData . setData (' Text ' Expose UI on OS X - treme Butter \" with action buttons .\n",
      "about : blank in location bar desynchronizes when closing tabs by default on OS X should include size and speed instead of requested website quickstart icon for Sted Sidebar extension inside ' customize toolbar dialog Home Page location textbox Forms pages just won ' t disappear even when url gives timeout when opened the cellar - an auction purchase of a felony , right ?\n",
      "Mom : You might be sleeping .\n",
      "It ' s better than Queer Eye for the ride .\n",
      "Fucking American cheese , pickles , onions , on its own .\n",
      "Woman : So you ' re doin '.\n",
      "Akeelah !\n",
      "Guy # 2 : I want to talk about princesses 24 hours .\n",
      "SOLDIER # 2 : How many times when hitting https site with badly named \" Mozilla \" Customize ...\" Options to open browser .\n",
      "Guy # 1 : Ew , no succulence , in the sand , and maybe my sister is going to go to fucking kill my mother ' s just do it ?\n",
      "I checked to see a brothel .\n",
      "Italian # 1 : Are you pregnant ?\"\n",
      "Girl # 1 : You got some cookies .\n",
      "Hobo : A posse .\n",
      "Woman : She just looked at me like it , and floats on the bus because it was okay because I spilled some on my fingers bleed .\n",
      "Come on , you gotta do something like is not a particularly good vintage for the ' Page Setup ' settings I have a sex change on 8th Ave by a bitter for my trouble ?\n",
      "Use Native Menus in default handlers list does not wear Prada .\n",
      "Girl : I put on my couch .\n",
      "ought to be taking my vibrator out for a remix ?\n",
      "Girl : Enjoy your party !\n",
      "Frustrated 30 - 50 .\n",
      "Teenboy : Umm no , wait , Elvis died on my IBM PC / Windows 95 double clicking OS Quick Launch toolbar reuses windows download doesn ' t automatically accept encodings different from UTF - 8 or not , you are beating the crap out of my face !\n",
      "What do you say that ?\n",
      "I don ' t matter .\n",
      "Little boy : Oh , well , it ' s your mother ... What ?\n",
      "Very fine .\n",
      "Man : I ' m going .\n",
      "Not anymore , though .\n",
      "Hold it !\n",
      "Man : Let ' s got it home , ' I just had it for installation to continue Firebird assumes location of start menu links to mozilla . org in Search Toolbar Crash when mousewheeling a form input fields hitting the tentacles start feeling around the dorm .\n",
      "A bit stinky at first base ?\n",
      "Husband : No , no one ' s not the problem is that she was like , a groopie ' s that song \" There is more than that on initially drinking a glass of poison ?\n",
      "Maybe they just into their sixth grade class and announces that their daughter just ate a cracker you found on the train and I got fired at Barely Legal !\n",
      "Hobo # 2 : ... Open up !\n",
      "When I go to Manhattan ?\n",
      "Confused shiksa : I don ' t do that again , I wouldn ' t they , like God had a baby ?\n",
      "Yarmulke man : It is hard to starboard .\n",
      "You never know where the marines enter ] [ Jack makes an odd bottle .\n",
      "You have to , uh -- ZOOT : Oh .\n",
      "People need to evacuate the train .\n",
      "We can damn near make blind people see and we need ?\n",
      "They ' re rich , low - cut white guy on cell : She did a speck of honest pirating .\n",
      "Guy # 2 : Yeah , totally your type !\n",
      "Guy # 1 : Did you hear I won ' t display correctly Firefox 0 . 8 overwrites default profile was still in Brooklyn accent : I would ' ve got a Friendster request from a single girl with a single black person .\n",
      "No toolbar context menu when no browser window open and you ' re also acting , right ?\n",
      "Guy : I used a few years .\n",
      "Guy # 1 : Wow , the cream that comes in a page times out when saving a file with same name by clicking link to a museum when you can ' t eat me \" box is broken by presence of something special .\n",
      "He does .\n",
      "It goes back to this folder \" Phoenix \" profile folder Crashes at start up with Bengay and shove it up for 30 sec ) to paste into image programs such as < img ... Back button is called Phoenix .\n",
      "Suit : Nope .\n",
      "Guy # 2 : No , I would never smash an avocado .\n",
      "Don ' t seem to remember empty password Java Console \" in \" Find in this morning .\n",
      "That ' s not gay .\n",
      "ARTHUR and BEDEVERE : My clit isn ' t have a really pointless discussion about apathy .\n",
      "That ' s fucking sick .\n",
      "Boy attorney # 2 : Do you ever wanted to eat snot .\n",
      "0 themes available when all of Milwaukee in four days , don ' t want to eat ?\n",
      "TIM : There are no more .\n",
      "Mom : Look , it ' s also proven that it makes you dumber the day that you love someone ... Queer : Because this guy on cell , taking the A train .\n",
      "[ the crowd stands silently on the download manager browser bobbing instead of Firebird is already installed in ~/. phoenix wont work Don ' t !\n",
      "Girl # 2 : She ' s , 5 ft 5 , disgorged March 04 .\n",
      "Why do people keep lying to me like I understand .\n",
      "Not often one has ever worked there has come back here !\n",
      "Not everyones idea of drinking semen not directly after the party and there were bite marks all over your house later to get your culo waxed .\n",
      "Grassy , very fine .\n",
      "and fell and slid about fifteen feet on the side of the men , Sir Launcelot from the popping out babies these days .\n",
      "Man : Why ?\n",
      "Chick : Um , I can get something to grab the key ?\n",
      "Is she a stripper ?\n",
      "\" Hey !\n",
      "as tooltips ) flash on this street I ' m totally ready to be generated Window locked after using Firefox 0 . 9 . 2 Causes \" INTERNAL ERROR on Browser End : No , .\n",
      "Just like that .\n"
     ]
    }
   ],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for sentence in webtext.sents():\n",
    "    for w1,w2,w3 in trigrams(sentence,pad_right=True,pad_left=True):\n",
    "        model[(w1,w2)][w3] += 1\n",
    "\n",
    "\n",
    "for w1,w2 in model:\n",
    "    total_count = float(sum(model[w1,w2].values()))\n",
    "    for w3 in model[w1,w2]:\n",
    "        model[w1,w2][w3] /= total_count\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(100):\n",
    "    text = [None, None]\n",
    "\n",
    "    sentence_finished = False\n",
    "\n",
    "    while not sentence_finished:\n",
    "        r = random.random()\n",
    "        accumulator = .0\n",
    "\n",
    "        word_prev = None\n",
    "        for word in model[tuple(text[-2:])].keys():\n",
    "            accumulator += model[tuple(text[-2:])][word]\n",
    "\n",
    "            if accumulator >= r:\n",
    "                text.append(word)\n",
    "                break\n",
    "\n",
    "            word_prev = word\n",
    "\n",
    "        if text[-2:] == [None, None]:\n",
    "            sentence_finished = True\n",
    "\n",
    "    print(' '.join([t for t in text if t]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! If you pay close attention you can see these sentences make more sense than bigrams sentences. Let's move even one step further and implement 4-gram. We can do this using n-gram library which takes length of history as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VILLAGER # 2 : you weren ' t such a dumbass it would get better .\n",
      "Bare **** Herby brown sugar , very attractive , drinking nicely .\n",
      "Chinese girl : Fine but eat something that makes it stand out .\n",
      "He ate 50 .\n",
      "Girl : Hmm - mm .\n",
      "Girl : I ' d like the walnut lentil pate .\n",
      "Don ' t even have time to poop .\n",
      "Long Island law student # 2 : Yeah , so lately I ' ve been thinking about you ' I just can ' t add anything to the \" grips . html \" which causes crash Preferences overwritten upgrading 0 . 8 crashes ( gpf ) when viewing www . atozwebtools . com download manager can not be cancelled nor removed from download manager are closed when all downloads complete Save all files to this folder doesn ' t restore toolbar When Uninstalled IE Ceases function due to error in GFXDRV . DRV URL - address line must not select text when clicked ONCE Hiting Alt - Enter in url location doesn ' t sell weed .\n",
      "Girl # 2 : Yeah , but who has more Chinky eyes ?\n",
      "Cop # 2 : Can we go now ?\n",
      "Appetising , nutty , good length and fine balanced acidity .\n",
      "Hispanic thug # 2 : Seriously , I need some food !\n",
      "Tourist : And this is my stop .\n",
      "Junkie girl : I ' m not sure yet , and I sleep well each night , thank you .\n",
      "Okay , I love going to Galapagos .\n",
      "Lady : Well is it famous ?\n",
      "Teen girl # 2 : No way !\n",
      "this entry .)\n",
      "This one coke dealer I met was like , ' What proposition ?'\n",
      "Girl on cell : Quite frankly I ' d do if I was going to be in the middle of the night , and it was dark and I wasn ' t your Compass work ?\n",
      "You wouldn ' t be cured .\n",
      "Vendor guy : Do you not fear death ?\n",
      "Woman : Yes .\n",
      "** Well put together tight wine , bright and elegant .\n",
      "Girl : No , he ' s , like , our periods stopped at the same time Parts of document get lost on Print or Print Preview Firefox shouldn ' t waste all that food ; there ' s a beast does the bidding of Davy Jones .\n",
      "Drier and tighter than the GA 97 too - lower dosage probably and perhaps the vintage too .\n",
      "Top *** Very pale - the colour has dropped out as sediment .\n",
      "Conductor # 3 : It ' s like they sense that it ' s a bookstore , nigga , or I ' m no whore .\n",
      "I need Viagra .\n",
      "Guy : But you wouldn ' t cross the street to die ?\n",
      "No , right ?\n",
      "An omelette ?\n",
      "Tourist woman : There ' s a gay porn star and we know all of this about him and we heard a click .\n",
      "Bare *** Doughy but floral nose , quite tight and with good pinot gutsiness .\n",
      "All I want is to find the head ] HADRUS : Vengo kowmpenay lachay .\n",
      "Blind man : Come on people , make some room .\n",
      "Teen boy : I hope they have tickets for Miss Saigon or King and I .\n",
      "Guy : They ' re addicted to food and it ' s okay though , he broke both of them .\n",
      "That I like to call the police .\n",
      "Just a fucking bitch , you couldn ' t say sorry to me !\n",
      "Real Champagne balance ( quite dry ) makes it pretty drinkable however , although it is hard to taste against great wines like the Gentaz , but only ** Dry , savoury , citric , a touch of yeast .\n",
      "Girl # 1 : less .\n",
      "Woman with eye patch : Some little kid poked it out .\n",
      "Woman # 1 : Hey !\n",
      "Chick : I told you I was going to love you !\n",
      "Learn that in life : never ask anyone anything ' cause they don ' t have to fuck around with everyone on the street to young couple kissing : Why do they keep doing that ?\n",
      "Very marmaladey .\n",
      "Building engineer # 1 : She was banging , and she says she has no right !\n",
      "Do you swear on your life ?!\n",
      "Mom : I will never pay for the New York Times ' new building , and one , who was Yasser Arafat ?\n",
      "Bare **** Very evolved colour .\n",
      "All right then , it ' s gotten to the point where I don ' t fit on that train .\n",
      "Thank you for offering me your seat , it is just simply very good .\n",
      "\"... Well , you ' re ugly , but healthy .\n",
      "This may be beginning to emerge .\n",
      "Girl # 1 : Shh , don√¢ &# x20AC ;&# x201D ;- because !\n",
      "Shit .\n",
      "Girl on cell : Hey , look at that Jetsons mom ' s is over , yo .\n",
      "Woman # 1 : Yeah , they ' d sell papers ?\n",
      "He was sitting in his BMW holding the wheel and falling asleep .\n",
      "How did this happen ?\n",
      "Frat boy # 2 : Uh huh .\n",
      "Fuck Mother in disheveled wildcat costume to crying son : It ' s not my fault .\n",
      "Girl # 2 : Are you drunk ?\n",
      "Guy : Nigga can tell a dishonest nigga by how eloquent he is .\n",
      "I won ' t stand those little bitches ; these are their friends or something ... and I like to wave at them as they pass by .\n",
      "Get out .\n",
      "Burn the witch !\n",
      "I ' ve killed everyone !\n",
      "This one had the good strawberry leather nose of the best vintages but does give a long mineral mouthful .\n",
      "ARTHUR : Surely you ' ve probably contracted multiple STD ' s just a number on the inside , he was so drunk , he was just so hot .\n",
      "Old man : Lady , would I be selling it if it weren ' t any .... what was that word you just said ?\n",
      "Guy # 2 : Yeah , but she ' s probably naked .\n",
      "The flavours however are very fine and nicely wrought .\n",
      "Message says success download in c : instead of specified drive [ Patch ] URI written in location bars doesn ' t make me dinner -- she ' s a blend of various varieties , for what it ' s 3 AM .\n",
      "Woman # 2 : Nope .\n",
      "On the other hand I can ' t use it that way ?\n",
      "Guy : That ' s pimp .\n",
      "Stranger : Thank you !\n",
      "Go back to the depths !\n",
      "Teen girl # 1 : Hey , bartender !\n",
      "( 50yo ) LJ seeks JS of Bayswater Be mine .\n",
      "Hipster boy : It ' s the commotion about ?\n",
      "Woman # 1 : Would you do Jessica Alba .... if there was a 25 % chance she was your sister ?\n",
      "* GIBBS : Lift the skin up !\n",
      "I said I was daft to build a new one .\n",
      "Teen boy : Dinosaurs are so stupid !\n",
      "JAP : Do you have any meatloaf ?\n",
      "Dry and austerely planky .\n",
      "White chick : Oh , you ' re not gonna wash your hands !\n",
      "Dude # 2 : Oh I know , I don ' t ever take the train , or the intoxicated , be sure to take them by the hand as there is a D train on the bridge .\n",
      "Passenger presses the ' Call attendant ' button .\n",
      "I ' ll buy you a drink .\n",
      "Very classic cedary , mature Claret .\n",
      "Chick on cell : She shouldn ' t steal .\n",
      "Spanish girl : Ew , no way .\n",
      "A bunch of black high school kids in ghetto garb pass two preppily dressed white girls and make loud catcalls at them .\n",
      "ARTHUR : Please !\n",
      "Penny , nickel , or dime ?\n",
      "Guy # 1 : But that ' s the problem ?\n",
      "But I told you my name like a hundred times .\n",
      "Security guard : Exit !\n",
      "She was like a size negative zero !\n",
      "Bare ***(**) Broader , more open on the nose scrapes ****\n",
      "Girl # 2 : Dude I swear to God , if some girl I was fucking horrible .\n",
      "Girl # 2 : Yeah .\n",
      "Hot chick : So , um , lyrical .\n",
      "Not that exciting to drink now - but it does have lovely round , sweet , leathery fruit and it has been open a while it seems even more Burgundian .\n",
      "Man : Keep an eye on my purse .\n",
      "It ' s just not a good idea .\n",
      "Soon they ' re really good and you don ' t have anything .\n",
      "High - toned .\n",
      "Focus lost until window unfocused + refocused when using autocomplete and a menu Migrates settings into Firefox without asking Open in Tabs does not work If Windows opens a new window instead of location line deleting downloads is extremely slow .\n",
      "High school girl # 1 : Because they kept asking too many questions .\n",
      "I really need because I can talk to me like that again , and I ' ve pissed the bed before .\n",
      "Shopgirl : They do make it harder on themselves , don ' t care , they ' re tracking your shoes .\n",
      "He ' s wearing a suit and sneakers !\n",
      "Drunk girl # 1 : It ' s frozen sunshine !\n",
      "Guy trying to whisper to girlfriend in line : Do not blame the bird .\n",
      "Teen boy # 2 : I know , that rooftop party -- and someone stole all my OxyContin .\n",
      "What are you ?\n",
      "JACK SPARROW : Move .\n",
      "Would be lovely except for that .\n",
      "It was mad red and shit , nigga !\n",
      "Girl : No .\n",
      "I got the dildo !\n",
      "*** Pleasant , fresh .\n",
      "Girl : Yes , George Bush will come and take you to jail .\n",
      "ELIZABETH SWANN : We ' re at the top left of the site , read the headless entry , and let your brilliance unfold .\n",
      "Homeboy : You look good though , lose a little weight ?\n",
      "Not yet .\n",
      "Guy # 1 : And I thought to myself , that ' s just like CeCe Peniston said : \" Keep on walkin ', I ain ' t grown yet .\n",
      "Guy # 2 : Who ?\n",
      "No outfit is cool unless you ' re on a motherfucking - packed subway .\n",
      "Guy : Damn , son .\n",
      "BEDEVERE : And therefore ?\n",
      "Guy : Anthrax ?\n",
      "Why don ' t know what to buy , but rather , on this showing .\n",
      "Good fruit and depth of colour .\n",
      "I ' ll have the perfectly peanut butter sundae .\n",
      "Knox area SINGLE MALE 45 seeks female 40 - 50 who are time poor from work / career and like fun times and nights in or out .\n",
      "Teen girl # 1 : And I thought to myself , \" God , I ' m not poor !\n",
      "DENNIS : I told her , don ' t have a cigarette .\n",
      "[ To friend , as man departs at Astor Place ] I didn ' t paint my toenails red after you made that comment .\n",
      "Rather higher acidity .\n",
      "WILL TURNER : What ?\n",
      "I don ' t know ... maybe the news was about .. like ... X - Men III , all high quality .\n",
      "I ' m staying at a hotel .\n",
      "I take the PATH train in .\n",
      "Tattooed chick : It ' s me front I ' m serious , you guys , like , 1 , 2 , 3 ... Woman to friend : Is she a stripper ?\n",
      "Guy : Then ... All of them .\n",
      "Queer : And they ' ll lock you up !\n",
      "GENT 57yrs of age , GSOH , DTE , Caring thats me 2 .\n",
      "Drunk guy : Sing us a song tonight !\n",
      "Tween boy # 2 ' s girlfriend ?\n",
      "Floral , mineral , riper , palate .\n",
      "Teenage girl : Yeah , for real .\n",
      "Teen girl # 2 : Do you vaguely resemble an elephant ?\n",
      "Father : Ah , but can you imagine if those other two came around the corner while he was doing the exam .\n",
      "All this after seeming a bit maderised at first , dissipates but perhaps takes the edge off .\n",
      "Woman : If they don ' t see no white niggers hatin ' on me , just my fellow brothers .\n",
      "But !\n",
      "Drunk ex - girlfriend : Oh , I love all of you together and create one big Frankenpussy .\"\n",
      "Old woman : Well , you know , the dog ?\n",
      "With the windows color scheme selected to high contrast black tools -> options crashes firebird with segmentation fault when loading a webpage when using dual monitors ( under windows ) Firefox GUI fails after launching Win2000 Terminal Services Middle - clicking in XML code tree causes page to vanish DOM Inspector persistent red paint problem if close window too early Cannot click OK button after opening \" Cookies | Exceptions \" Add Bookmark \" dialogue Memory Cache Limit Size is too small .\n",
      "Not Rated Depths , depths and more depths .\n",
      "Teen guy : Yeah , I that ' s so easy to find a smaller one .\n",
      "BRIDGEKEEPER : Stop !\n",
      "Crackhead : Ladies and gentlemen , the captain will be dimming the cabin lighting , as it greatly improves the attractiveness of your in - flight crew .\n",
      "A very easy ****\n",
      "AM New York guy : AM New York guy : Motherfuckers , you betta check this shit out !\n",
      "You put your sword right through his head !\n",
      "Autoscroll in Firebird 0 . 7 + crashes when I try to visit www . php . net crashes Firefox and Moz 1 . 4 .\n",
      "Girl on cell : What ?\n",
      "Interesting , quite complex .\n",
      "If I see a little border in black ( only at top and left borders ) when I play a flash object Options > downloads > UI widen file types list GTK1 and 2 Build Page Info - page size is not screen resolution - dependent Moving downloaded file from tmp folder should not freeze main browser windows I have w2k with admin and user accounts Firebird crashed when you enter a one - eyed , homeless black guy to think you ' re too old to be in the Navy .\n",
      "Your hair is ugly .\n",
      "Thirtysomething woman : You cut in front of that fat bastard .\n",
      "****(*) Tobacco - leaf , elegant , fragrant fruit .\n",
      "Girl : But you already have a Big Mac ... Hobo : Oh , I am the taxi .\n",
      "White guy : Fucking visas , man .\n",
      "We ' re going to see on the IMAX tomorrow .\n",
      "Very nice .\n",
      "not prompted to save login at Wikipedia bookmarks subdirectory does not appear .\n",
      "C ' mon , you know ?\n",
      "[ later still ] Eva Amurri to hipster companion : My father was telling me the dangers of aspartame -- you know .\n",
      "Little girl : Why do they call it \" Steak Shack \" when it doesn ' t restore focus to page request : bookmarks and history open in new windows instead of sidebars Wrong icon in finder open a second Preferences window browser crashes on page load Firefox paint performance when scrolling page with flash in a new window is opened bookmarks dropdown does not expand after removing some elemnts by kontekst menu Memory not freed after I close tabs failed menu collapse causes keyboard functionality to be lost New Portrait and Landscape icons are not saved The \" advanced browsing \" preference shows \" XML Parsing Error in chrome :// pippki / content browser screen flashes for 0 . 5 second every time a browser window is missing an icon I wish the search bar ( searchplugin box ) Your browser sent a query this server could not understand .\n",
      "Girl : Stop staring at all the buildings , you look like Amy Fisher ?\n",
      "CRONE : No !\n",
      "*** Intense strawberry nose , solid , quite raisiny .\n",
      "Shit already !\n",
      "She flips him off .\n",
      "Thug , taking a drink : Yo , do you think I am ?\n",
      "A great sailor , until he ran afoul of dat which vex all men .\n",
      "Store guy : I ' ve been eating really good foods .\n",
      "Street vendor becomes nervous and looks around .\n",
      "Teen girl # 1 : But damn , she ' s nine months pregnant .\n",
      "Modern - style - revert to Aqua style buttons Error with xpcom . dll library while visiting some pages Height of Toolbars and Tabs - should be more recognizeable as menu same status bar text for all tabs Evangelism : MBNA ' s Online Payment system recognizes Firefox as old version of Netscape ctrl + K doesn ' t close properly upon shutdown of the program why set a homepage if you have one of those judgmental going - to - medium weight claret with classic cigar box .\n",
      "Tourist mom : Museum of what ?\n",
      "You will offer what amounts to a full pardon .\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for sentence in webtext.sents():\n",
    "    for w1,w2,w3,w4 in ngrams(sentence,4,pad_right=True,pad_left=True):\n",
    "        model[(w1,w2,w3)][w4] += 1\n",
    "\n",
    "\n",
    "for w1,w2,w3 in model:\n",
    "    total_count = float(sum(model[w1,w2,w3].values()))\n",
    "    for w4 in model[w1,w2,w3]:\n",
    "        model[w1,w2,w3][w4] /= total_count\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(200):\n",
    "    text = [None, None,None]\n",
    "\n",
    "    sentence_finished = False\n",
    "\n",
    "    while not sentence_finished:\n",
    "        r = random.random()\n",
    "        accumulator = .0\n",
    "\n",
    "        word_prev = None\n",
    "        for word in model[tuple(text[-3:])].keys():\n",
    "            accumulator += model[tuple(text[-3:])][word]\n",
    "\n",
    "            if accumulator >= r:\n",
    "                text.append(word)\n",
    "                break\n",
    "\n",
    "            word_prev = word\n",
    "\n",
    "        if text[-3:] == [None, None,None]:\n",
    "            sentence_finished = True\n",
    "\n",
    "    print(' '.join([t for t in text if t]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice! Isn't it interesting such a simple concept and model can produce such interesting sentences!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
